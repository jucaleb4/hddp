{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3260fcc8-e2e6-4b9d-98e0-277d24831280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87065afb-8233-481d-8b06-601e6ba7d948",
   "metadata": {},
   "source": [
    "# Tuning Evaluation\n",
    "\n",
    "This script contains code to examine the tuning performance. We start with $\\gamma=0.8$ on the hierarchical inventory problem.\n",
    "\n",
    "Note that this experiment was performed when the initial value was uniformally selected from $[0,1]^n$. We should select from $\\overline{ub} \\cdot [0,1]^n$, where $\\overline{ub}$ is an upper bound on the state variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09463f12-9852-48a0-9ed0-003ac9bad17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_seed_data(fname):\n",
    "    arr = np.squeeze(pd.read_csv(fname).to_numpy())\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0520d9c7-67cc-4d56-bf06-6cbe5b081cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"/Users/calebju/Code/hddp/logs/2025_03_28/exp_0\"\n",
    "\n",
    "n_0 = 36\n",
    "n_files = 36\n",
    "arr = np.zeros((n_files,1), dtype=float)\n",
    "n_cut_arr = np.zeros(n_files)\n",
    "min_score, min_i = np.inf, -1\n",
    "for i in range(n_files):\n",
    "    data = get_eval_seed_data(os.path.join(folder, \"run_%d/eval_seed=0.csv\" % (i+n_0)))\n",
    "    num_cuts = len(get_eval_seed_data(os.path.join(folder, \"run_%d/vals.csv\" % (i+n_0))))\n",
    "    if len(data) > arr.shape[1]:\n",
    "        arr = np.hstack((arr, np.zeros((n_files, len(data) - arr.shape[1]))))\n",
    "    arr[i,:len(data)] = data\n",
    "    if data[-1] < min_score:\n",
    "        min_score = data[-1]\n",
    "        min_i = i\n",
    "    print(\"Exp %i final score: %.4e (%d cuts)\" % (i + n_0, data[-1], num_cuts))\n",
    "\n",
    "print(\"Best exp: %i with score %.4e\" % (min_i + n_0, min_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c25603-75d3-49c6-8ffc-c7bc7f9937e0",
   "metadata": {},
   "source": [
    "### Performance of hueristics\n",
    "\n",
    "As a sanity check, let us see how the best compares to four different hueristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d6d4d2-3698-43f3-bb10-5d29beea3eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"/Users/calebju/Code/hddp/logs/2025_03_30/exp_0\"\n",
    "\n",
    "n_files = 120\n",
    "arr = np.zeros((n_files,1), dtype=float)\n",
    "min_score, min_i = np.inf, -1\n",
    "for i in range(0,n_files,30):\n",
    "    data = get_eval_seed_data(os.path.join(folder, \"run_%d/eval_seed=0.csv\" % i))\n",
    "    if len(data) > arr.shape[1]:\n",
    "        arr = np.hstack((arr, np.zeros((n_files, len(data) - arr.shape[1]))))\n",
    "    arr[i,:len(data)] = data\n",
    "    if data[-1] < min_score:\n",
    "        min_score = data[-1]\n",
    "        min_i = i\n",
    "    print(\"Exp %i final score: %.4e\" % (i, data[-1]))\n",
    "\n",
    "print(\"Best exp: %i with score %.4e\" % (min_i, min_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828b2d0-e66d-4251-b5e3-d260475a8a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
