{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dbfb3e-57b6-4982-9de7-d6ce1d97b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b6fcaa-fd07-43c8-80c7-d739c1b10051",
   "metadata": {},
   "source": [
    "# Out of Sample Evaluation\n",
    "\n",
    "This notebook is dedicated to plotting out-of-sample performance.\n",
    "\n",
    "### Inventory with secondary assembly\n",
    "\n",
    "Based on the `tuning_eval.ipynb`, which chose `k1=20`, `k2=20`, `eta1=0.1` and `eta2=1` for the PDSA solver for $\\gamma=0.8$. We chose `k1=100`, `k2=20`, `eta1=1`, and `eta2=0.01` for $\\gamma=0.99$. Since the subproblems are similar (up to the previous search point), we use these parameters for all EDDP variants we ran.\n",
    "\n",
    "Previously (before adding bounds on the cost-to-go), the best bounds were `k1=100`, `k2=20`, `eta1=1` and `eta2=0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a0064-2c8d-4840-9f73-ef358438f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_seed_data(fname):\n",
    "    if not os.path.isfile(fname):\n",
    "        return np.zeros(0)\n",
    "    arr = np.squeeze(pd.read_csv(fname).to_numpy())\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56224d4-ddac-4735-badc-9ab479e98d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"/Users/calebju/Code/hddp/logs/2025_04_02/exp_0\"\n",
    "mode_name_arr = [\"Inf-EDDP\", \"GCE-Inf-EDDP\", \"C_Inf-SDDP\", \"SDDP\"]\n",
    "\n",
    "n_exp = 8\n",
    "n_seeds = 30\n",
    "arr = np.zeros((n_exp, n_seeds), dtype=float)\n",
    "for i in range(n_exp):\n",
    "    mode_name = mode_name_arr[i % 4]\n",
    "    print(\"Mode: %s\" % mode_name)\n",
    "    \n",
    "    cut_arr = get_eval_seed_data(os.path.join(folder, \"run_%d/vals.csv\" % i))\n",
    "    if len(cut_arr) == 0:\n",
    "        print(\"Exp %d not run yet, skipping\" % i)\n",
    "        continue\n",
    "    num_cuts = len(cut_arr)\n",
    "    for j in range(n_seeds):\n",
    "        data = get_eval_seed_data(os.path.join(folder, \"run_%d/eval_seed=%d.csv\" % (i,j)))\n",
    "        if len(data) == 0:\n",
    "            print(\"Exp %d not run yet, skipping\" % i)\n",
    "            break\n",
    "        arr[i,j] = data[-1]\n",
    "\n",
    "    print(\"Exp %d cuts: %d\" % (i, num_cuts))\n",
    "    print(\"Exp %d avg final score: %.16e\" % (i, np.mean(arr[i])))\n",
    "    print(\"Exp %d std final score: %.16e\" % (i, np.std(arr[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1ac28a-5872-4c31-b889-ce2eadda6b86",
   "metadata": {},
   "source": [
    "The performance between Inf-EDDP (exp 0) and Inf-SDDP (exp 1) is so similar. Let's take their final scores differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47846fb6-6d5c-4160-93b5-af496bfa969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"/Users/calebju/Code/hddp/logs/2025_04_02/exp_0\"\n",
    "\n",
    "n_exp = 2\n",
    "n_seeds = 30\n",
    "arr = np.zeros((2,n_seeds), dtype=float)\n",
    "for i in range(n_exp):\n",
    "    num_cuts = len(cut_arr)\n",
    "    for j in range(n_seeds):\n",
    "        data = get_eval_seed_data(os.path.join(folder, \"run_%d/eval_seed=%d.csv\" % (i,j)))\n",
    "        arr[i,j] = data[-1]\n",
    "\n",
    "np.diff(arr, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486d30b6-c6af-4232-a0d4-efb2ecf73fa1",
   "metadata": {},
   "source": [
    "Now we plot the performance as a histogram. Since all non-traditional-SDDP methods achieved identical performance, we arbitrarily select GCE-Inf-EDDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f96c6a9-ede0-4d24-8568-4e9ace9cb66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "bins = 50 * np.arange(16,24) \n",
    "ax = plt.subplot()\n",
    "ax.hist(arr[1], bins=bins, color=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9620d1b2-93ec-4a5c-a23d-bffebcd6f4b9",
   "metadata": {},
   "source": [
    "We see they are indeed different, but very very similar. It seems random sampling does not deviate too much from explorative in this problem.\n",
    "\n",
    "### Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0398888b-c721-4bdf-8527-237a0f011542",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"/Users/calebju/Code/hddp/logs/2025_03_30/exp_0\"\n",
    "mode_name_arr = [\"PID(0)\", \"PID(25)\", \"PID(50)\", \"Myopic\"]\n",
    "\n",
    "n_exp = 8\n",
    "n_seeds = 30\n",
    "arr = np.zeros((n_exp, n_seeds), dtype=float)\n",
    "for i in range(n_exp):\n",
    "    mode_name = mode_name_arr[i % 4]\n",
    "    print(\"Mode: %s\" % mode_name)\n",
    "    early_stop = 0\n",
    "    for j in range(n_seeds):\n",
    "        data = get_eval_seed_data(os.path.join(folder, \"run_%d/eval_seed=%d.csv\" % (i,j)))\n",
    "        if len(data) == 0:\n",
    "            print(\"Exp %d not run yet, skipping\" % i)\n",
    "            early_stop = 1\n",
    "            break\n",
    "        arr[i,j] = data[-1]\n",
    "\n",
    "    if not early_stop:\n",
    "        # print(arr)\n",
    "        print(\"Exp %d avg final score: %.16e\" % (i, np.mean(arr[i])))\n",
    "        print(\"Exp %d std final score: %.16e\" % (i, np.std(arr[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb4774-8d30-4ec4-81c9-79defe69f052",
   "metadata": {},
   "source": [
    "Now we plot the histogram of the best performing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ebd35-c695-4a71-aa67-6be10e411a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot()\n",
    "ax.hist(arr[2], bins=bins, color=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58122da2-0021-4628-b694-8aa0a9ff53e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
